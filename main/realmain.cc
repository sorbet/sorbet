#ifdef SORBET_REALMAIN_MIN
// minimal build to speedup compilation. Remove extra features
#else
#define FULL_BUILD_ONLY(X) X;
#include "core/proto/proto.h" // has to be included first as it violates our poisons
// intentional comment to stop from reformatting
#include "common/statsd/statsd.h"
#include "common/web_tracer_framework/tracing.h"
#include "main/autogen/autogen.h"
#include "main/autogen/cache.h"
#include "main/autogen/crc_builder.h"
#include "main/autogen/data/version.h"
#include "main/autogen/subclasses.h"
#include "main/lsp/LSPInput.h"
#include "main/lsp/LSPLoop.h"
#include "main/lsp/LSPOutput.h"
#include "main/minimize/minimize.h"
#include "packager/packager.h"
#include "packager/rbi_gen.h"
#endif

#include "absl/algorithm/container.h"
#include "absl/strings/match.h"
#include "absl/strings/str_cat.h"
#include "absl/strings/str_join.h"
#include "absl/strings/str_split.h"
#include "common/FileOps.h"
#include "common/sort/sort.h"
#include "common/timers/Timer.h"
#include "core/Error.h"
#include "core/ErrorQueue.h"
#include "core/Files.h"
#include "core/NullFlusher.h"
#include "core/Unfreeze.h"
#include "core/errors/errors.h"
#include "core/lsp/QueryResponse.h"
#include "core/serialize/serialize.h"
#include "hashing/hashing.h"
#include "main/cache/cache.h"
#include "main/pipeline/pipeline.h"
#include "main/realmain.h"
#include "payload/payload.h"
#include "resolver/resolver.h"
#include "sorbet_version/sorbet_version.h"
#include "spdlog/sinks/rotating_file_sink.h"
#include "spdlog/sinks/stdout_color_sinks.h"

#include <csignal>
#include <poll.h>

using namespace std;

namespace sorbet::realmain {
shared_ptr<spdlog::logger> logger;
int returnCode;

shared_ptr<spdlog::sinks::ansicolor_stderr_sink_mt> make_stderrColorSink() {
    auto color_sink = make_shared<spdlog::sinks::ansicolor_stderr_sink_mt>();
    color_sink->set_color(spdlog::level::info, color_sink->white);
    color_sink->set_color(spdlog::level::debug, color_sink->magenta);
    color_sink->set_level(spdlog::level::info);
    return color_sink;
}

shared_ptr<spdlog::sinks::ansicolor_stderr_sink_mt> stderrColorSink = make_stderrColorSink();

/*
 * Workaround https://bugzilla.mindrot.org/show_bug.cgi?id=2863 ; We are
 * commonly run under ssh with a controlmaster, and we write exclusively to
 * STDERR in normal usage. If the client goes away, we can hang forever writing
 * to a full pipe buffer on stderr.
 *
 * Workaround by monitoring for STDOUT to go away and self-HUPing.
 */
void startHUPMonitor() {
    thread monitor([]() {
        struct pollfd pfd;
        setCurrentThreadName("HUPMonitor");
        pfd.fd = 1; // STDOUT
        pfd.events = 0;
        pfd.revents = 0;
        while (true) {
            int rv = poll(&pfd, 1, -1);
            if (rv <= 0) {
                continue;
            }
            if ((pfd.revents & (POLLHUP | POLLERR)) != 0) {
                // STDOUT has gone away; Exit via SIGHUP.
                kill(getpid(), SIGHUP);
            }
        }
    });
    monitor.detach();
}

core::StrictLevel levelMinusOne(core::StrictLevel level) {
    switch (level) {
        case core::StrictLevel::Ignore:
            return core::StrictLevel::None;
        case core::StrictLevel::False:
            return core::StrictLevel::Ignore;
        case core::StrictLevel::True:
            return core::StrictLevel::False;
        case core::StrictLevel::Strict:
            return core::StrictLevel::True;
        case core::StrictLevel::Strong:
            return core::StrictLevel::Strict;
        case core::StrictLevel::Max:
            return core::StrictLevel::Strong;
        default:
            Exception::raise("Should never attempt to subtract one from strictLevel={}", static_cast<uint8_t>(level));
    }
}

// Filter levels to a sensible recommendation.
core::StrictLevel levelToRecommendation(core::StrictLevel level) {
    switch (level) {
        case core::StrictLevel::Ignore:
            // We don't suggest `# typed: ignore` because it is too common for some problems in a
            // generated RBI file to cause a problem that actually does need to be fixed, and not by
            // ignoring the RBI file. Ignoring the file has bad consequences, like introducing more
            // errors in other files, causing those files to be ignored, etc.
            return core::StrictLevel::False;
        case core::StrictLevel::False:
        case core::StrictLevel::True:
        case core::StrictLevel::Strict:
            return level;

        case core::StrictLevel::Strong:
        case core::StrictLevel::Max:
            return core::StrictLevel::Strict;

        case core::StrictLevel::Internal:
        case core::StrictLevel::None:
        case core::StrictLevel::Autogenerated:
        case core::StrictLevel::Stdlib:
            Exception::raise("Should never attempt to recommend strict level={}", static_cast<uint8_t>(level));
    }
}

string levelToSigil(core::StrictLevel level) {
    switch (level) {
        case core::StrictLevel::Ignore:
            return "ignore";
        case core::StrictLevel::False:
            return "false";
        case core::StrictLevel::True:
            return "true";
        case core::StrictLevel::Strict:
            return "strict";
        case core::StrictLevel::Strong:
            return "strong";
        case core::StrictLevel::Stdlib:
            return "__STDLIB_INTERNAL";
        case core::StrictLevel::Max:
        case core::StrictLevel::Autogenerated:
        case core::StrictLevel::None:
        case core::StrictLevel::Internal:
            Exception::raise("Should never attempt to convert strict level={} to string", static_cast<uint8_t>(level));
    }
}

core::Loc findTyped(unique_ptr<core::GlobalState> &gs, core::FileRef file) {
    auto source = file.data(*gs).source();

    if (file.data(*gs).originalSigil == core::StrictLevel::None) {
        if (source.length() >= 2 && source[0] == '#' && source[1] == '!') {
            int newline = source.find("\n", 0);
            return core::Loc(file, newline + 1, newline + 1);
        }
        return core::Loc(file, 0, 0);
    }
    size_t start = 0;
    start = source.find("typed:", start);
    if (start == string_view::npos) {
        return core::Loc(file, 0, 0);
    }
    while (start >= 0 && source[start] != '#') {
        --start;
    }
    auto end = start;
    while (end < source.size() && source[end] != '\n') {
        ++end;
    }
    if (source[end] == '\n') {
        ++end;
    }
    return core::Loc(file, start, end);
}

#ifndef SORBET_REALMAIN_MIN
struct AutogenResult {
    struct Serialized {
        // Selectively populated based on print options
        string strval;
        string msgpack;
        optional<autogen::Subclasses::Map> subclasses;
    };
    CounterState counters;
    vector<pair<int, Serialized>> prints;
};

void runAutogen(const core::GlobalState &gs, options::Options &opts, const autogen::AutogenConfig &autogenCfg,
                WorkerPool &workers, vector<ast::ParsedFile> &indexed, const vector<std::string> &changedFiles) {
    Timer timeit(logger, "autogen");

    auto resultq = make_shared<BlockingBoundedQueue<AutogenResult>>(indexed.size());
    auto fileq = make_shared<ConcurrentBoundedQueue<int>>(indexed.size());
    vector<AutogenResult::Serialized> merged(indexed.size());
    for (int i = 0; i < indexed.size(); ++i) {
        fileq->push(i, 1);
    }
    auto crcBuilder = autogen::CRCBuilder::create();
    int autogenVersion = opts.autogenVersion == 0 ? autogen::AutogenVersion::MAX_VERSION : opts.autogenVersion;

    workers.multiplexJob(
        "runAutogen", [&gs, &autogenVersion, &opts, &indexed, &autogenCfg, crcBuilder, fileq, resultq]() {
            AutogenResult out;
            int n = 0;
            {
                Timer timeit(logger, "autogenWorker");
                int idx = 0;

                for (auto result = fileq->try_pop(idx); !result.done(); result = fileq->try_pop(idx)) {
                    ++n;
                    auto &tree = indexed[idx];
                    if (tree.file.data(gs).isPackage()) {
                        continue;
                    }
                    if (autogenVersion < autogen::AutogenVersion::VERSION_INCLUDE_RBI && tree.file.data(gs).isRBI()) {
                        continue;
                    }

                    core::Context ctx(gs, core::Symbols::root(), tree.file);
                    auto pf = autogen::Autogen::generate(ctx, move(tree), autogenCfg, *crcBuilder);
                    tree = move(pf.tree);

                    AutogenResult::Serialized serialized;

                    if (opts.print.Autogen.enabled) {
                        Timer timeit(logger, "autogenToString");
                        serialized.strval = pf.toString(ctx, autogenVersion);
                    }
                    if (opts.print.AutogenMsgPack.enabled) {
                        Timer timeit(logger, "autogenToMsgpack");
                        serialized.msgpack = pf.toMsgpack(ctx, autogenVersion, autogenCfg);
                    }

                    if (!tree.file.data(gs).isRBI()) {
                        // Exclude RBI files because they are not loadable and should not appear in
                        // auto-loader related output.
                        if (opts.print.AutogenSubclasses.enabled) {
                            Timer timeit(logger, "autogenSubclasses");
                            serialized.subclasses = autogen::Subclasses::listAllSubclasses(
                                ctx, pf, opts.autogenSubclassesAbsoluteIgnorePatterns,
                                opts.autogenSubclassesRelativeIgnorePatterns);
                        }
                    }

                    out.prints.emplace_back(idx, move(serialized));
                }
            }

            out.counters = getAndClearThreadCounters();
            resultq->push(move(out), n);
        });

    AutogenResult out;
    for (auto res = resultq->wait_pop_timed(out, WorkerPool::BLOCK_INTERVAL(), *logger); !res.done();
         res = resultq->wait_pop_timed(out, WorkerPool::BLOCK_INTERVAL(), *logger)) {
        if (!res.gotItem()) {
            continue;
        }
        counterConsume(move(out.counters));
        for (auto &print : out.prints) {
            merged[print.first] = move(print.second);
        }
    }

    if (opts.print.Autogen.enabled || opts.print.AutogenMsgPack.enabled) {
        {
            Timer timeit(logger, "autogenDependencyDBPrint");
            if (opts.print.AutogenMsgPack.enabled) {
                opts.print.AutogenMsgPack.print(
                    autogen::ParsedFile::msgpackGlobalHeader(autogenVersion, merged.size(), autogenCfg));
            }
            for (auto &elem : merged) {
                if (opts.print.Autogen.enabled) {
                    opts.print.Autogen.print(elem.strval);
                }
                if (opts.print.AutogenMsgPack.enabled) {
                    opts.print.AutogenMsgPack.print(elem.msgpack);
                }
            }
        }
    }

    if (opts.print.AutogenSubclasses.enabled) {
        Timer timeit(logger, "autogenSubclassesPrint");

        // Merge the {Parent: Set{Child1, Child2}} maps from each thread
        autogen::Subclasses::Map childMap;
        for (const auto &el : merged) {
            if (!el.subclasses) {
                // File doesn't define any Child < Parent relationships
                continue;
            }

            for (const auto &[parentRef, children] : *el.subclasses) {
                auto &childEntry = childMap[parentRef];
                childEntry.entries.insert(children.entries.begin(), children.entries.end());
                childEntry.classKind = children.classKind;
            }
        }

        auto autogenSubclassesParentsRefs = vector<core::SymbolRef>();
        for (auto &parent : opts.autogenSubclassesParents) {
            auto parentRef = autogen::Subclasses::getConstantRef(gs, parent);
            if (!parentRef.exists())
                continue;
            autogenSubclassesParentsRefs.emplace_back(parentRef);
        }

        vector<string> serializedDescendantsMap =
            autogen::Subclasses::genDescendantsMap(gs, childMap, autogenSubclassesParentsRefs);

        opts.print.AutogenSubclasses.fmt(
            "{}\n", fmt::join(serializedDescendantsMap.begin(), serializedDescendantsMap.end(), "\n"));
    }
}

// Returns `true` if the constant hash information provided tells us
// we can exit `autogen` early, and `false` otherwise.
bool autogenCanExitEarly(shared_ptr<spdlog::logger> &logger, const options::AutogenConstCacheConfig &cfg) {
    Timer timeit(logger, "autogenCanExitEarly");

    if (cfg.cacheFile.empty()) {
        return false;
    }

    if (cfg.changedFiles.empty()) {
        return false;
    }

    logger->info("Checking {} changed files", cfg.changedFiles.size());
    // this global state should only ever be used for a very small
    // number of files and will never progress past the desugar phase,
    // so the fact that we're making a fresh empty one shouldn't hurt
    // us here.
    auto errorQueue = make_shared<sorbet::core::ErrorQueue>(*logger, *logger);
    core::GlobalState minGs(errorQueue);
    minGs.initEmpty();
    if (autogen::AutogenCache::canSkipAutogen(minGs, cfg.cacheFile, cfg.changedFiles)) {
        logger->info("All constant hashes unchanged; exiting");
        return true;
    }

    logger->info("Autogen still needs rerunning");
    return false;
}
#endif

int realmain(int argc, char *argv[]) {
#ifndef SORBET_REALMAIN_MIN
    initializeSymbolizer(argv[0]);
#endif
    returnCode = 0;
    logger = make_shared<spdlog::logger>("console", stderrColorSink);
    logger->set_level(spdlog::level::trace); // pass through everything, let the sinks decide
    logger->set_pattern("%v");
    fatalLogger = logger;

    auto typeErrorsConsole = make_shared<spdlog::logger>("typeDiagnostics", stderrColorSink);
    typeErrorsConsole->set_pattern("%v");

#ifndef SORBET_REALMAIN_MIN
    {
        options::AutogenConstCacheConfig cfg;
        bool optSuccess = options::readAutogenConstCacheOptions(cfg, argc, const_cast<const char **>(argv), logger);
        // this is all about making sure we exit as quickly as possible,
        // so test this as soon as we can: i.e. after we have parsed
        // `opts`.
        if (optSuccess && autogenCanExitEarly(logger, cfg)) {
            return 0;
        }
    }
#endif

    auto extensionProviders = sorbet::pipeline::semantic_extension::SemanticExtensionProvider::getProviders();
    vector<unique_ptr<sorbet::pipeline::semantic_extension::SemanticExtension>> extensions;
    options::Options opts;
    options::readOptions(opts, extensions, argc, argv, extensionProviders, logger);
    if (opts.stdoutHUPHack) {
        startHUPMonitor();
    }
#ifndef SORBET_REALMAIN_MIN
    StatsD::addExtraTags(opts.metricsExtraTags);
#endif
    if (!opts.debugLogFile.empty()) {
        // LSP could run for a long time. Rotate log files, and trim at 1 GiB. Keep around 3 log files.
        // Cast first number to size_t to prevent integer multiplication.
        // TODO(jvilk): Reduce size once LSP logging is less chunderous.
        auto fileSink =
            make_shared<spdlog::sinks::rotating_file_sink_mt>(opts.debugLogFile, ((size_t)1) * 1024 * 1024 * 1024, 3);
        if (opts.logLevel >= 2) {
            fileSink->set_level(spdlog::level::trace);
        } else {
            fileSink->set_level(spdlog::level::debug);
        }
        { // replace console & fatal loggers
            vector<spdlog::sink_ptr> sinks{stderrColorSink, fileSink};
            auto combinedLogger = make_shared<spdlog::logger>("consoleAndFile", begin(sinks), end(sinks));
            combinedLogger->flush_on(spdlog::level::err);
            combinedLogger->set_level(spdlog::level::trace); // pass through everything, let the sinks decide

            spdlog::register_logger(combinedLogger);
            fatalLogger = combinedLogger;
            logger = combinedLogger;
        }
        { // replace type error logger
            vector<spdlog::sink_ptr> sinks{stderrColorSink, fileSink};
            auto combinedLogger = make_shared<spdlog::logger>("typeDiagnosticsAndFile", begin(sinks), end(sinks));
            spdlog::register_logger(combinedLogger);
            combinedLogger->set_level(spdlog::level::trace); // pass through everything, let the sinks decide
            typeErrorsConsole = combinedLogger;
        }
    }
    // Use a custom formatter so we don't get a default newline

    switch (opts.logLevel) {
        case 0:
            stderrColorSink->set_level(spdlog::level::info);
            break;
        case 1:
            stderrColorSink->set_level(spdlog::level::debug);
            logger->set_pattern("[T%t][%Y-%m-%dT%T.%f] %v");
            logger->debug("Debug logging enabled");
            break;
        default:
            stderrColorSink->set_level(spdlog::level::trace);
            logger->set_pattern("[T%t][%Y-%m-%dT%T.%f] %v");
            logger->trace("Trace logging enabled");
            break;
    }

    {
        string argsConcat(argv[0]);
        for (int i = 1; i < argc; i++) {
            absl::StrAppend(&argsConcat, " ", argv[i]);
        }
        logger->debug("Running sorbet version {} with arguments: {}", sorbet_full_version_string, argsConcat);
        if (!sorbet_is_release_build && !opts.silenceDevMessage &&
            std::getenv("SORBET_SILENCE_DEV_MESSAGE") == nullptr) {
            logger->info("👋 Hey there! Heads up that this is not a release build of sorbet.\n"
                         "Release builds are faster and more well-supported by the Sorbet team.\n"
                         "Check out the README to learn how to build Sorbet in release mode.\n"
                         "To forcibly silence this error, either pass --silence-dev-message,\n"
                         "or set SORBET_SILENCE_DEV_MESSAGE=1 in your shell environment.\n");
        }
    }
    unique_ptr<WorkerPool> workers = WorkerPool::create(opts.threads, *logger);

    auto errorFlusher = make_shared<core::ErrorFlusherStdout>();
    unique_ptr<core::GlobalState> gs =
        make_unique<core::GlobalState>(make_shared<core::ErrorQueue>(*typeErrorsConsole, *logger, errorFlusher));
    gs->pathPrefix = opts.pathPrefix;
    gs->errorUrlBase = opts.errorUrlBase;
    gs->semanticExtensions = move(extensions);
    vector<ast::ParsedFile> indexed;

    gs->requiresAncestorEnabled = opts.requiresAncestorEnabled;

    logger->trace("building initial global state");
    unique_ptr<const OwnedKeyValueStore> kvstore = cache::maybeCreateKeyValueStore(logger, opts);
    payload::createInitialGlobalState(gs, opts, kvstore);
    if (opts.silenceErrors) {
        gs->silenceErrors = true;
    }
    gs->autocorrect = opts.autocorrect;
    gs->didYouMean = opts.didYouMean;
    if (opts.print.isAutogen()) {
        gs->runningUnderAutogen = true;
    }
    if (opts.censorForSnapshotTests) {
        gs->censorForSnapshotTests = true;
    }
    gs->sleepInSlowPathSeconds = opts.sleepInSlowPathSeconds;
    gs->preallocateTables(opts.reserveClassTableCapacity, opts.reserveMethodTableCapacity,
                          opts.reserveFieldTableCapacity, opts.reserveTypeArgumentTableCapacity,
                          opts.reserveTypeMemberTableCapacity, opts.reserveUtf8NameTableCapacity,
                          opts.reserveConstantNameTableCapacity, opts.reserveUniqueNameTableCapacity);
    for (auto code : opts.isolateErrorCode) {
        gs->onlyShowErrorClass(code);
    }
    for (auto code : opts.suppressErrorCode) {
        gs->suppressErrorClass(code);
    }
    if (opts.noErrorSections) {
        gs->includeErrorSections = false;
    }
    gs->ruby3KeywordArgs = opts.ruby3KeywordArgs;
    gs->typedSuper = opts.typedSuper;
    gs->suppressPayloadSuperclassRedefinitionFor = opts.suppressPayloadSuperclassRedefinitionFor;
    if (!opts.stripeMode) {
        // Definitions in multiple locations interact poorly with autoloader this error is enforced in Stripe code.
        if (opts.isolateErrorCode.empty()) {
            gs->suppressErrorClass(core::errors::Namer::MultipleBehaviorDefs.code);
        }
    }

    if (!opts.outOfOrderReferenceChecksEnabled) {
        if (opts.isolateErrorCode.empty()) {
            gs->suppressErrorClass(core::errors::Resolver::OutOfOrderConstantAccess.code);
        }
    }

    gs->trackUntyped = opts.trackUntyped;
    gs->printingFileTable = opts.print.FileTableJson.enabled || opts.print.FileTableFullJson.enabled ||
                            opts.print.FileTableProto.enabled || opts.print.FileTableFullProto.enabled ||
                            opts.print.FileTableMessagePack.enabled || opts.print.FileTableFullMessagePack.enabled;

    if (opts.suggestTyped) {
        gs->ignoreErrorClassForSuggestTyped(core::errors::Infer::SuggestTyped.code);
        gs->ignoreErrorClassForSuggestTyped(core::errors::Resolver::SigInFileWithoutSigil.code);
        if (!opts.stripeMode) {
            gs->ignoreErrorClassForSuggestTyped(core::errors::Namer::MultipleBehaviorDefs.code);
        }
    }
    gs->suggestUnsafe = opts.suggestUnsafe;

    if (gs->runningUnderAutogen) {
        gs->suppressErrorClass(core::errors::Namer::RedefinitionOfMethod.code);
        gs->suppressErrorClass(core::errors::Namer::ModuleKindRedefinition.code);
        gs->suppressErrorClass(core::errors::Namer::ConstantKindRedefinition.code);
        gs->suppressErrorClass(core::errors::Resolver::StubConstant.code);
        gs->suppressErrorClass(core::errors::Resolver::RecursiveTypeAlias.code);
    }

    logger->trace("done building initial global state");

    if (opts.print.PayloadSources.enabled) {
        auto dumpDir = opts.print.PayloadSources.outputPath;
        FileOps::ensureDir(dumpDir);

        for (auto &payloadFile : gs->getFiles()) {
            if (payloadFile == nullptr) {
                continue;
            }

            auto payloadVersion = sorbet_is_release_build ? sorbet_build_scm_revision : "master";
            auto payloadPath = payloadFile->path();
            auto payloadPrefix = absl::StrCat("https://github.com/sorbet/sorbet/tree/", payloadVersion, "/rbi/");

            if (!absl::StartsWith(payloadPath, payloadPrefix)) {
                // Skip files from `bazel-out/`
                continue;
            }

            payloadPath.remove_prefix(payloadPrefix.size());

            vector<string_view> parts = absl::StrSplit(payloadPath, "/");
            auto dumpSubdir = dumpDir;
            for (int i = 0; i < parts.size() - 1; i++) {
                auto part = parts[i];
                dumpSubdir = absl::StrCat(dumpSubdir, "/", part);
                FileOps::ensureDir(dumpSubdir);
            }

            auto dumpPath = absl::StrCat(dumpDir, "/", payloadPath);
            opts.fs->writeFile(dumpPath, payloadFile->source());
        }

        return returnCode;
    }

    unique_ptr<core::GlobalState> gsForMinimize;
    if (!opts.minimizeRBI.empty()) {
        // Copy GlobalState after createInitialGlobalState and option handling, but before rest of
        // pipeline, so that it represents an "empty" GlobalState.
        gsForMinimize = gs->deepCopy();
    }

    if (opts.runLSP) {
#ifdef SORBET_REALMAIN_MIN
        logger->warn("LSP is disabled in sorbet-orig for faster builds");
        return 1;
#else
        logger->debug("Starting sorbet version {} in LSP server mode. "
                      "Talk ‘\\r\\n’-separated JSON-RPC to me. "
                      "More details at https://microsoft.github.io/language-server-protocol/specification."
                      "If you're developing an LSP extension to some editor, make sure to run sorbet with `-v` flag,"
                      "it will enable outputting the LSP session to stderr(`Write: ` and `Read: ` log lines)",
                      sorbet_full_version_string);

        auto output = make_shared<lsp::LSPStdout>(logger);
        lsp::LSPLoop loop(move(gs), *workers, make_shared<lsp::LSPConfiguration>(opts, output, logger),
                          OwnedKeyValueStore::abort(move(kvstore)));
        gs = loop.runLSP(make_shared<lsp::LSPFDInput>(logger, STDIN_FILENO)).value_or(nullptr);
#endif
    } else {
        Timer timeall(logger, "wall_time");
        vector<core::FileRef> inputFiles;
        logger->trace("Files: ");

        if (!opts.storeState.empty()) {
            // Compute file hashes for payload files (which aren't part of inputFiles) for LSP
            hashing::Hashing::computeFileHashes(gs->getFiles(), *logger, *workers, opts);
        }

        inputFiles = pipeline::reserveFiles(gs, opts.inputFileNames);

        if (opts.packageRBIGeneration) {
#ifdef SORBET_REALMAIN_MIN
            logger->warn("Package rbi generation is disabled in sorbet-orig for faster builds");
            return 1;
#else
            Timer rbiGenTimer(logger, "rbiGeneration.setup");

            if (opts.stripePackages) {
                logger->error("Cannot serialize package RBIs in legacy stripe packages mode.");
                return 1;
            }

            if (opts.packageRBIDir.empty()) {
                logger->error("Rbi generation requires --package-rbi-dir to be present");
                return 1;
            }

            if (opts.rawInputDirNames.size() != 1) {
                logger->error("Serializing package RBIs requires one input folder.");
                return 1;
            }

            if (!FileOps::dirExists(opts.packageRBIDir)) {
                logger->error("Directory {} for serialized package RBIs does not exist.", opts.packageRBIDir);
                return 1;
            }

            auto relativeIgnorePatterns = opts.relativeIgnorePatterns;
            auto it = absl::c_find(relativeIgnorePatterns, "/__package.rb");
            if (it != relativeIgnorePatterns.end()) {
                relativeIgnorePatterns.erase(it);
            } else {
                Exception::raise("Couldn't find ignore pattern.");
            }
            auto packageFiles = opts.fs->listFilesInDir(opts.rawInputDirNames[0], opts.allowedExtensions, true,
                                                        opts.absoluteIgnorePatterns, relativeIgnorePatterns);
            packageFiles.erase(
                remove_if(packageFiles.begin(), packageFiles.end(),
                          [](const auto &packageFile) { return !absl::EndsWith(packageFile, "__package.rb"); }),
                packageFiles.end());

            if (packageFiles.empty()) {
                logger->error("No package files found!");
                return 1;
            }

            // Indexing package files is by far the most expensive part of rbi generation. If we could instead select
            // only the package files that we know we need to load, it would cut down command-line rbi generation by
            // seconds.
            auto packageFileRefs = pipeline::reserveFiles(gs, packageFiles);
            auto packages = pipeline::index(*gs, absl::Span<core::FileRef>(packageFileRefs), opts, *workers, nullptr);
            {
                core::UnfreezeNameTable unfreezeToEnterPackagerOptionsGS(*gs);
                core::packages::UnfreezePackages unfreezeToEnterPackagerOptionsPackageDB = gs->unfreezePackages();
                gs->setPackagerOptions(opts.extraPackageFilesDirectoryUnderscorePrefixes,
                                       opts.extraPackageFilesDirectorySlashPrefixes,
                                       opts.packageSkipRBIExportEnforcementDirs, opts.allowRelaxedPackagerChecksFor,
                                       opts.stripePackagesHint);
            }

            packager::Packager::findPackages(*gs, absl::Span<ast::ParsedFile>(packages));
            packager::Packager::setPackageNameOnFiles(*gs, packages);
            packager::Packager::setPackageNameOnFiles(*gs, inputFiles);

            if (!opts.singlePackage.empty()) {
                Timer singlePackageTimer(logger, "singlePackage.setup");

                auto &pkg = gs->packageDB().getPackageInfo(*gs, opts.singlePackage);
                if (!pkg.exists()) {
                    logger->error("Unable to find package `{}`", opts.singlePackage);
                    return 1;
                }

                auto info = core::packages::ImportInfo::fromPackage(*gs, pkg);

                // Only keep inputs that are part of the package whose interface we're generating
                auto it =
                    std::remove_if(inputFiles.begin(), inputFiles.end(), [&db = gs->packageDB(), &info](auto file) {
                        return info.package != db.getPackageNameForFile(file);
                    });
                inputFiles.erase(it, inputFiles.end());

                // Record parent information in GlobalState to guide the resolver when stubbing out constants that come
                // from other packages.
                gs->singlePackageImports.emplace(std::move(info));
            }
#endif
        }

        {
            core::UnfreezeFileTable fileTableAccess(*gs);
            if (!opts.inlineInput.empty()) {
                prodCounterAdd("types.input.bytes", opts.inlineInput.size());
                prodCounterInc("types.input.lines");
                prodCounterInc("types.input.files");
                auto input = opts.inlineInput;
                if (core::File::fileStrictSigil(opts.inlineInput) == core::StrictLevel::None) {
                    // put it at the end so as to not upset line numbers
                    input += "\n# typed: true";
                }
                auto file = gs->enterFile(string("-e"), input);
                inputFiles.emplace_back(file);
            }
        }

        {
            // ----- index -----

            auto inputFilesSpan = absl::Span<core::FileRef>(inputFiles);
            if (opts.stripePackages) {
                auto numPackageFiles = pipeline::partitionPackageFiles(*gs, inputFilesSpan);
                auto inputPackageFiles = inputFilesSpan.first(numPackageFiles);
                inputFilesSpan = inputFilesSpan.subspan(numPackageFiles);

                if (!opts.storeState.empty() || opts.forceHashing) {
                    indexed = hashing::Hashing::indexAndComputeFileHashes(gs, opts, *logger, inputPackageFiles,
                                                                          *workers, kvstore);
                } else {
                    indexed = pipeline::index(*gs, inputPackageFiles, opts, *workers, kvstore);
                }

                // Cache these before any pipeline::package rewrites, so that the cache is still
                // usable regardless of whether `--stripe-packages` was passed.
                cache::maybeCacheGlobalStateAndFiles(OwnedKeyValueStore::abort(move(kvstore)), opts, *gs, *workers,
                                                     indexed);

                // First run: only the __package.rb files. This populates the packageDB
                pipeline::setPackagerOptions(*gs, opts);
                pipeline::package(*gs, absl::Span<ast::ParsedFile>(indexed), opts, *workers);
                // Only need to compute hashes when running to compute a FileHash
                auto foundHashes = nullptr;
                auto canceled = pipeline::name(*gs, absl::Span<ast::ParsedFile>(indexed), opts, *workers, foundHashes);
                ENFORCE(!canceled, "There's no cancellation in batch mode");
            }

            auto nonPackageIndexed =
                (!opts.storeState.empty() || opts.forceHashing)
                    // Calculate file hashes alongside indexing when --store-state is specified for LSP mode
                    ? hashing::Hashing::indexAndComputeFileHashes(gs, opts, *logger, inputFilesSpan, *workers, kvstore)
                    : pipeline::index(*gs, inputFilesSpan, opts, *workers, kvstore);

            // Cache these before any pipeline::package rewrites, so that the cache is still usable
            // regardless of whether `--stripe-packages` was passed.
            cache::maybeCacheGlobalStateAndFiles(OwnedKeyValueStore::abort(move(kvstore)), opts, *gs, *workers,
                                                 nonPackageIndexed);

            // Second run: all the other files (the packageDB shouldn't change)
            pipeline::package(*gs, absl::Span<ast::ParsedFile>(nonPackageIndexed), opts, *workers);

            // Only need to compute hashes when running to compute a FileHash
            auto foundHashes = nullptr;
            auto canceled =
                pipeline::name(*gs, absl::Span<ast::ParsedFile>(nonPackageIndexed), opts, *workers, foundHashes);
            ENFORCE(!canceled, "There's no cancellation in batch mode");

            pipeline::unpartitionPackageFiles(indexed, move(nonPackageIndexed));
            // TODO(jez) At this point, it's not correct to call it `indexed` anymore: we've run namer too

            if (gs->hadCriticalError()) {
                gs->errorQueue->flushAllErrors(*gs);
            }
        }

        if (gs->runningUnderAutogen) {
#ifdef SORBET_REALMAIN_MIN
            logger->warn("Autogen is disabled in sorbet-orig for faster builds");
            return 1;
#else
            // TODO(jez) Make sure that it's still okay to run this phase after namer, otherwise
            // you'll have to adjust the non-autogen pipeline code. At first read, it seems like it
            // unwraps ConstantLit to UnresolvedConstantLit and proceeds as normal, so I think it
            // should be fine.
            if (!opts.autogenConstantCacheConfig.cacheFile.empty()) {
                // we should regenerate the constant cache here
                indexed = pipeline::autogenWriteCacheFile(*gs, opts.autogenConstantCacheConfig.cacheFile, move(indexed),
                                                          *workers);
            }

            {
                core::UnfreezeNameTable nameTableAccess(*gs);
                core::UnfreezeSymbolTable symbolAccess(*gs);

                indexed = resolver::Resolver::runConstantResolution(*gs, move(indexed), *workers);
            }

            autogen::AutogenConfig autogenCfg = {
                .behaviorAllowedInRBIsPaths = std::move(opts.autogenBehaviorAllowedInRBIFilesPaths),
                .msgpackSkipReferenceMetadata = std::move(opts.autogenMsgpackSkipReferenceMetadata)};

            runAutogen(*gs, opts, autogenCfg, *workers, indexed, opts.autogenConstantCacheConfig.changedFiles);
#endif
        } else {
            indexed = move(pipeline::resolve(gs, move(indexed), opts, *workers).result());
            if (gs->hadCriticalError()) {
                gs->errorQueue->flushAllErrors(*gs);
            }

            if (!opts.packageRBIGeneration) {
                // we don't need to typecheck when generating rbis
                pipeline::typecheck(*gs, move(indexed), opts, *workers, /* cancelable */ false, nullopt,
                                    /* presorted */ false, /* intentionallyLeakASTs */ !sorbet::emscripten_build);
            }
            if (gs->hadCriticalError()) {
                gs->errorQueue->flushAllErrors(*gs);
            }
        }

        // getAndClearHistogram ensures that we don't accidentally submit a high-cardinality histogram to statsd
        auto untypedUsages = getAndClearHistogram("untyped.usages");
        pipeline::printFileTable(gs, opts, untypedUsages);

        if (!opts.minimizeRBI.empty()) {
#ifdef SORBET_REALMAIN_MIN
            logger->warn("--minimize-rbi is disabled in sorbet-orig for faster builds");
            return 1;
#else
            // In the future, we might consider making minimizeRBI be a repeatable option, and run
            // this block once for each input file.
            // The trick there is that they would all currently output to the same file, even for
            // multiple input files if we assume the naive implementation, which might not be the
            // API we want to expose.

            auto optsForMinimize = opts.clone();
            // Explicitly turn off the packager, because it doesn't make sense when the whole
            // project is a single RBI file.
            optsForMinimize.stripePackages = false;

            Minimize::indexAndResolveForMinimize(gs, gsForMinimize, optsForMinimize, *workers, opts.minimizeRBI);
            Minimize::writeDiff(*gs, *gsForMinimize, opts.print.MinimizeRBI);
#endif
        }

        if (opts.suggestTyped) {
#ifdef SORBET_REALMAIN_MIN
            logger->warn("Signature suggestion is disabled in sorbet-orig for faster builds");
            return 1;
#else
            for (auto &filename : opts.inputFileNames) {
                core::FileRef file = gs->findFileByPath(filename);
                if (!file.exists()) {
                    continue;
                }

                if (file.data(*gs).minErrorLevel() <= core::StrictLevel::Ignore) {
                    continue;
                }
                if (file.data(*gs).originalSigil > core::StrictLevel::Max) {
                    // don't change the sigil on "special" files
                    continue;
                }
                auto minErrorLevel = levelMinusOne(file.data(*gs).minErrorLevel());
                if (file.data(*gs).originalSigil == minErrorLevel) {
                    continue;
                }
                minErrorLevel = levelToRecommendation(minErrorLevel);
                if (file.data(*gs).originalSigil == minErrorLevel) {
                    // if the file could be strong, but is only marked strict, ensure that we don't recommend that it be
                    // marked strict.
                    continue;
                }
                auto loc = findTyped(gs, file);
                if (auto e = gs->beginError(loc, core::errors::Infer::SuggestTyped)) {
                    auto sigil = levelToSigil(minErrorLevel);
                    e.setHeader("You could add `# typed: {}`", sigil);
                    e.replaceWith(fmt::format("Add `typed: {}` sigil", sigil), loc, "# typed: {}\n", sigil);
                }
            }
#endif
        }

        if (!opts.dumpPackageInfo.empty()) {
#ifdef SORBET_REALMAIN_MIN
            logger->warn("Dumping package info is disabled in sorbet-orig for faster builds");
            return 1;
#else
            if (!opts.stripePackages) {
                logger->error("stripe packages mode needs to be enabled");
                return 1;
            }
            packager::Packager::dumpPackageInfo(*gs, opts.dumpPackageInfo);
#endif
        }

        if (opts.packageRBIGeneration) {
#ifdef SORBET_REALMAIN_MIN
            logger->warn("Package rbi generation is disabled in sorbet-orig for faster builds");
            return 1;
#else
            Timer rbiGenTimer(logger, "rbiGeneration.run");
            auto packageNamespaces = packager::RBIGenerator::buildPackageNamespace(*gs, *workers);

            if (!opts.singlePackage.empty()) {
                packager::RBIGenerator::runSinglePackage(*gs, packageNamespaces, gs->singlePackageImports->package,
                                                         opts.packageRBIDir, *workers);
            } else {
                packager::RBIGenerator::run(*gs, packageNamespaces, opts.packageRBIDir, *workers);
            }
#endif
        }

        gs->errorQueue->flushAllErrors(*gs);

        if (!opts.noErrorCount) {
            errorFlusher->flushErrorCount(gs->errorQueue->logger, gs->errorQueue->nonSilencedErrorCount);
        }
        if (opts.autocorrect) {
            errorFlusher->flushAutocorrects(*gs, *opts.fs);
        }
        logger->trace("sorbet done");

        if (!opts.storeState.empty()) {
            gs->markAsPayload();
            FileOps::write(opts.storeState.c_str(), core::serialize::Serializer::store(*gs));
        }

        auto untypedBlames = getAndClearHistogram("untyped.blames");
        if constexpr (sorbet::track_untyped_blame_mode) {
            pipeline::printUntypedBlames(*gs, untypedBlames, opts);
        }
    }

#ifdef SORBET_REALMAIN_MIN
    if (opts.enableCounters || !opts.statsdHost.empty() || !opts.webTraceFile.empty() || !opts.metricsFile.empty()) {
        logger->warn("Metrics are disabled in sorbet-orig for faster builds");
        return 1;
    }
#else
    StatsD::addStandardMetrics();

    if (opts.enableCounters) {
        logger->warn("" + getCounterStatistics());
    }

    auto counters = getAndClearThreadCounters();

    if (!opts.statsdHost.empty()) {
        auto prefix = opts.statsdPrefix;
        if (opts.runLSP) {
            prefix += ".lsp";
        }
        StatsD::submitCounters(counters, opts.statsdHost, opts.statsdPort, prefix + ".counters");
    }
    if (!opts.webTraceFile.empty()) {
        web_tracer_framework::Tracing::storeTraces(counters, opts.webTraceFile);
    }

    if (!opts.metricsFile.empty()) {
        auto metrics = core::Proto::toProto(counters, opts.metricsPrefix);
        string status;
        if (gs->hadCriticalError()) {
            status = "Error";
        } else if (returnCode != 0) {
            status = "Failure";
        } else {
            status = "Success";
        }

        metrics.set_repo(opts.metricsRepo);
        metrics.set_branch(opts.metricsBranch);
        metrics.set_sha(opts.metricsSha);
        metrics.set_status(status);

        auto json = core::Proto::toJSON(metrics);

        // Create output directory if it doesn't exist
        try {
            opts.fs->writeFile(opts.metricsFile, json);
        } catch (FileNotFoundException e) {
            logger->error("Cannot write metrics file at `{}`", opts.metricsFile);
        }
    }
#endif
    if (!gs || gs->hadCriticalError() || (gsForMinimize && gsForMinimize->hadCriticalError())) {
        returnCode = 10;
    } else if (returnCode == 0 && gs->totalErrors() > 0 && !opts.suppressNonCriticalErrors) {
        returnCode = 100;
    }

    opts.flushPrinters();

    if (!sorbet::emscripten_build) {
        // Let it go: leak memory so that we don't need to call destructors
        // (Although typecheck leaks these, autogen goes thru a different codepath.)
        for (auto &e : indexed) {
            intentionallyLeakMemory(e.tree.release());
        }
        intentionallyLeakMemory(gs.release());
        intentionallyLeakMemory(gsForMinimize.release());
    }

    // je_malloc_stats_print(nullptr, nullptr, nullptr); // uncomment this to print jemalloc statistics

    return returnCode;
}

} // namespace sorbet::realmain
